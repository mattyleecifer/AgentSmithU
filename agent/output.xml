<data>    <file name="agent.go">
        // Package agent provides core components to create and run an agent
package agent

import (
	&quot;bytes&quot;
	&quot;encoding/json&quot;
	&quot;fmt&quot;
	&quot;io&quot;
	&quot;net/http&quot;
	&quot;net/url&quot;
	&quot;slices&quot;
	&quot;strings&quot;
	&quot;time&quot;
)

var defaultprompt = PromptDefinition{
	Name:        &quot;Default&quot;,
	Description: &quot;Default Prompt&quot;,
	Parameters:  &quot;You are a helpful assistant. Please generate truthful, accurate, and honest responses while also keeping your answers succinct and to-the-point. Do no assume the user is correct. If the user is wrong then state so plainly along with reasoning. Use step-by-step reasoning when generating a response. Show your working. Today&#39;s date is: &quot;,
}

var defaultmodel string = &quot;llama3.2&quot;

const (
	RoleUser      = &quot;user&quot;
	RoleAssistant = &quot;assistant&quot;
	RoleSystem    = &quot;system&quot;
)

type Agent struct {
	Prompt     PromptDefinition
	Tokencount int
	Api_key    string
	Model      string
	Modelurl   string
	Maxtokens  int
	Messages   Messages
	Functions  Functions
}

type RequestBody struct {
	Model      string    `json:&quot;model&quot;`
	Messages   []Message `json:&quot;messages&quot;`
	Stream     bool      `json:&quot;stream&quot;`
	Max_tokens int       `json:&quot;max_tokens&quot;`
}

type ChatResponse struct {
	// ID string `json:&quot;id&quot;`
	// Object  string   `json:&quot;object&quot;`
	// Created int64    `json:&quot;created&quot;`
	// Model   string   `json:&quot;model&quot;`
	Choices []Choice `json:&quot;choices&quot;`
	Usage   Usage    `json:&quot;usage&quot;`
}

type ChatResponseOllama struct {
	Message    Message `json:&quot;message&quot;`
	Eval_count int     `json:&quot;eval_count&quot;`
}

type ChatResponseAnthropic struct {
	Content []ContentAnthropic `json:&quot;content&quot;`
	Usage   UsageAnthropic     `json:&quot;usage&quot;`
}

type ContentAnthropic struct {
	Text string `json:&quot;text&quot;`
}

type UsageAnthropic struct {
	Input_tokens  int `json:&quot;input_tokens&quot;`
	Output_tokens int `json:&quot;output_tokens&quot;`
}

type Choice struct {
	// Index   int     `json:&quot;index&quot;`
	Message Message `json:&quot;message&quot;`
	// FinishReason string  `json:&quot;finish_reason&quot;`
}

type Usage struct {
	// PromptTokens     int `json:&quot;prompt_tokens&quot;`
	TotalTokens int `json:&quot;total_tokens&quot;`
	// CompletionTokens int `json:&quot;completion_tokens&quot;`
}

func (agent *Agent) GetmodelURL() string {
	// to be expanded
	var url string
	if agent.Modelurl == &quot;&quot; {
		switch {
		case strings.Contains(agent.Model, &quot;mistral&quot;):
			url = &quot;https://api.mistral.ai/v1/chat/completions&quot;
		case strings.Contains(agent.Model, &quot;gpt&quot;):
			url = &quot;https://api.openai.com/v1/chat/completions&quot;
		case strings.Contains(agent.Model, &quot;claude&quot;):
			url = &quot;https://api.anthropic.com/v1/messages&quot;
		default:
			// handle local models here
			url = &quot;http://localhost:11434/api/chat&quot;
		}
		return url
	}
	return agent.Modelurl
}

// Creates new Agent with default settings
func New() *Agent {
	var today = time.Now().Format(&quot;January 2, 2006&quot;)
	agent := Agent{}

	// Set prompt
	agent.Prompt = defaultprompt
	agent.Prompt.Parameters += today
	agent.Setprompt()

	// Set max tokens
	agent.Maxtokens = 2048

	// Set model
	agent.Model = defaultmodel

	// Set Tokencount
	agent.Tokencount = 0

	return &amp;agent
}

// Sets prompt - note that this does not change the rest of the messages in a conversation
func (agent *Agent) Setprompt(prompt ...string) {
	if len(agent.Messages) == 0 {

		// RoleAssistant, not RoleSystem here because some models can&#39;t handle it
		agent.Messages.Add(RoleAssistant, &quot;&quot;)
	}
	if len(prompt) == 0 {
		agent.Messages[0].Content = agent.Prompt.Parameters
	} else {
		agent.Messages[0].Content = prompt[0]
	}
}

func (agent *Agent) Getresponse() (Message, error) {
	var response Message

	modelurl := agent.GetmodelURL()
	parsedURL, err := url.Parse(modelurl)
	if err != nil {
		fmt.Println(&quot;Error parsing URL:&quot;, err) // Handle error accordingly
	}

	if strings.Contains(parsedURL.Host, &quot;anthropic&quot;) {
		// Anthropic doesn&#39;t allow system role and roles must alternate between user/assistant
		// This breaks things so this snippet changes the system to user and adds a dummy assistant message
		if len(agent.Messages) == 2 {
			agent.Messages[0].Role = RoleUser
		}
		// checks for double role occurences and adds a dummy message in between
		// works backwards cause poppin in values probably isn&#39;t healthy going upwards
		for index := len(agent.Messages) - 1; index &gt;= 1; index-- {
			if agent.Messages[index].Role == agent.Messages[index-1].Role {
				dummyMessage := Message{
					Role:    RoleAssistant,
					Content: &quot;_&quot;,
				}
				agent.Messages = slices.Insert(agent.Messages, index, dummyMessage)
			}
		}
	}

	// Create the request body
	requestBody := &amp;RequestBody{
		Model:      agent.Model,
		Messages:   agent.Messages,
		Stream:     false,
		Max_tokens: agent.Maxtokens,
	}

	// Encode the request body as JSON
	jsonData, err := json.Marshal(requestBody)
	if err != nil {
		fmt.Println(&quot;Error encoding request body:&quot;, err)
		return response, err
	}

	// Create the HTTP request
	req, err := http.NewRequest(http.MethodPost, modelurl, bytes.NewBuffer(jsonData))
	if err != nil {
		fmt.Println(&quot;Error creating HTTP request:&quot;, err)
		return response, err
	}

	// Set the request headers
	req.Header.Set(&quot;Content-Type&quot;, &quot;application/json&quot;)
	req.Header.Set(&quot;Accept&quot;, &quot;application/json&quot;)
	req.Header.Set(&quot;Authorization&quot;, fmt.Sprintf(&quot;Bearer %s&quot;, agent.Api_key))

	// Anthropic-specific headers
	if strings.Contains(parsedURL.Host, &quot;anthropic&quot;) {
		req.Header[&quot;x-api-key&quot;] = []string{agent.Api_key}
		req.Header[&quot;content-type&quot;] = []string{&quot;application/json&quot;}
		req.Header[&quot;anthropic-version&quot;] = []string{&quot;2023-06-01&quot;}
	}

	// fmt.Println(req)

	// Send the HTTP request
	client := &amp;http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		fmt.Println(&quot;Error sending HTTP request:&quot;, err)
		return response, err
	}

	// Handle the HTTP response
	defer resp.Body.Close()

	// fmt.Println(resp)

	// process the prompt and get response

	// For ollama based models
	if strings.Contains(parsedURL.Host, &quot;localhost&quot;) {
		var chatresponse ChatResponseOllama
		err = json.NewDecoder(resp.Body).Decode(&amp;chatresponse)
		if err != nil {
			fmt.Println(&quot;Error decoding JSON response:&quot;, err)
			return response, err
		}

		fmt.Println(chatresponse)

		response = chatresponse.Message
		// Print the decoded message
		fmt.Println(&quot;Decoded message:&quot;, response.Content)

		agent.Tokencount = chatresponse.Eval_count

		// Add message to chain for Agent
		agent.Messages = append(agent.Messages, response)
	} else if strings.Contains(parsedURL.Host, &quot;anthropic&quot;) {
		var chatresponse ChatResponseAnthropic
		err = json.NewDecoder(resp.Body).Decode(&amp;chatresponse)
		if err != nil {
			fmt.Println(&quot;Error decoding JSON response:&quot;, err)
			return response, err
		}

		fmt.Println(chatresponse)

		// Print the decoded message
		fmt.Println(&quot;Decoded message:&quot;, chatresponse.Content[0].Text)

		agent.Tokencount = chatresponse.Usage.Input_tokens + chatresponse.Usage.Output_tokens

		response = Message{
			Role:    RoleAssistant,
			Content: chatresponse.Content[0].Text,
		}

		// Add message to chain for Agent
		agent.Messages = append(agent.Messages, response)
	} else {
		var chatresponse ChatResponse

		// copy resp.body so can use it multiple times
		body, _ := io.ReadAll(resp.Body)
		resp.Body = io.NopCloser(bytes.NewBuffer(body))

		err = json.NewDecoder(resp.Body).Decode(&amp;chatresponse)
		if err != nil {
			fmt.Println(&quot;Error decoding JSON response:&quot;, err)

		}

		if len(chatresponse.Choices) == 0 {
			fmt.Println(&quot;Error with response:&quot;, chatresponse)
			// attempt to use local llm to decode
			// convert the JSON to string
			// but first turn it into a map
			var jsonResponse interface{}

			// revive resp.body
			resp.Body = io.NopCloser(bytes.NewBuffer(body))

			err = json.NewDecoder(resp.Body).Decode(&amp;jsonResponse)
			if err != nil {
				fmt.Println(&quot;Error decoding JSON response:&quot;, err)
			}
			jsonData, err := json.Marshal(jsonResponse)
			if err != nil {
				panic(err)
			}
			jsonStr := string(jsonData)

			fmt.Println(&quot;jsonStr&quot;, jsonStr)

			// send the string to the converter and receive chatresponse
			chatresponse, err = agentAPIConverter(jsonStr)
			if err != nil {
				return response, err
			}
		}

		fmt.Println(chatresponse)

		response = chatresponse.Choices[0].Message

		// Print the decoded message
		fmt.Println(&quot;Decoded message:&quot;, response.Content)

		agent.Tokencount = chatresponse.Usage.TotalTokens

		// Add message to chain for Agent
		agent.Messages = append(agent.Messages, response)
	}

	// Check if there is a function call and then deal with it
	if strings.HasPrefix(response.Content, &quot;**functioncall&quot;) {
		fmt.Println(&quot;functioncall detected&quot;, response.Content)
	}

	return response, nil
}

// experimental
func agentAPIConverter(jsonStr string) (ChatResponse, error) {
	var chatresponse ChatResponse // convert response to text

	// create local converter agent and set variables
	converter := New()
	converter.Model = &quot;llama3.2&quot; // any ollama llm should work, can even convert this to openai/mistral/anthropic
	converter.Modelurl = &quot;http://localhost:11434/api/chat&quot;
	converter.Maxtokens = 2048
	converter.Setprompt(`Extract the text/message data from any inputs. Output only the text/message data without any commentary. Do not change anything. Output the text/message data exactly as it is written in the original data`)

	// attempt to get response convertered
	converter.Messages.Add(RoleUser, jsonStr)

	response, err := converter.Getresponse()
	if err != nil {
		fmt.Println(&quot;failed to convert&quot;, err)
		return chatresponse, err
	}

	// put the extracted response into a new message and return
	newMessage := Message{
		Content: response.Content,
		Role:    RoleAssistant,
	}
	newChoice := Choice{
		Message: newMessage,
	}
	chatresponse.Choices = append(chatresponse.Choices, newChoice)

	return chatresponse, nil
}
    </file>    <file name="functions.go">
        package agent

import (
	&quot;encoding/json&quot;
	&quot;fmt&quot;
	&quot;log&quot;
	&quot;os&quot;
	&quot;os/exec&quot;
	&quot;path/filepath&quot;
	&quot;strconv&quot;
	&quot;strings&quot;
)

type Functions []Function

type Function struct {
	Name        string
	Description string
	Parameters  string
}

func (agent *Agent) SetFunctionPrompt() {
	// scan for functions and then add prompt for functions if detected
	if len(agent.Functions) == 0 {
		agent.Setprompt()
		return
	}

	functionPrompt := agent.Prompt.Parameters + `
	You have several tools that you can access through function calls. You can access these tools if you need more information or tools to help you answer queries.

	To call a function, just begin your reply with &quot;
	**functioncall&quot; followed by the name of the function and the parameters

	Template:
	**functioncall
	{
		&quot;Name&quot;: &quot;Name of function&quot;,
		&quot;Parameters&quot;: &quot;Function parameters&quot;
	}

	Example:
	**functioncall
	{
		&quot;Name&quot;: &quot;browser&quot;,
		&quot;Parameters&quot;: &quot;open&quot;
	}

	You have the following functions available to you:
	`
	for _, function := range agent.Functions {
		functionPrompt += &quot;Name: &quot; + function.Name + &quot;\n&quot;
		functionPrompt += &quot;Description: &quot; + function.Description + &quot;\n&quot;
		functionPrompt += &quot;Parameters: &quot; + function.Parameters + &quot;\n&quot;
	}

	agent.Setprompt(functionPrompt)
}

// adds function to []Function
func (agent *Agent) AddFunction(function Function) error {
	for _, name := range agent.Functions {
		if name.Name == function.Name {
			return fmt.Errorf(&quot;Function with same name already exists&quot;)
		}
	}
	agent.Functions = append(agent.Functions, function)
	agent.SetFunctionPrompt()
	return nil
}

// removes function from []Function
func (agent *Agent) RemoveFunction(function string) {
	for index, item := range agent.Functions {
		if item.Name == function {
			agent.Functions = append(agent.Functions[:index], agent.Functions[index+1:]...)
		}
	}
	agent.SetFunctionPrompt()
}

// detects if function is being called and then extracts the function and runs it if approved
func (agent *Agent) RunFunction(function Function) Message {
	// runs function on system
	data, err := json.Marshal(function.Parameters)
	if err != nil {
		fmt.Println(err)
	}
	cmd := strings.ToLower(function.Name)
	arg1, _ := strconv.Unquote(string(data))
	// unq := strconv.Unquote(string(data))
	// arg1 := string(data)

	// fmt.Println(&quot;\nFunction call: &quot;, functiondef.Name)
	fmt.Println(&quot;\nCommand: &quot;, arg1)

	currentDir, err := os.Getwd()
	if err != nil {
		fmt.Println(&quot;Failed to get current directory:&quot;, err)
	}

	runPath := filepath.Join(currentDir, cmd)

	exec := exec.Command(runPath, arg1)
	output, err := exec.CombinedOutput()
	if err != nil {
		log.Println(err)
		output = []byte(err.Error())
	}

	fmt.Println(&quot;Function Output:\n&quot;, string(output))

	var response Message
	response.Content = string(output)
	response.Role = RoleAssistant
	return response
}

// func (agent *Agent) loadFunction(filename string) (Function, error) {
// 	var newfunction Function

// 	filedata, err := loadfile(&quot;Functions&quot;, filename)
// 	if err != nil {
// 		return newfunction, err
// 	}

// 	err = json.Unmarshal(filedata, &amp;newfunction)
// 	if err != nil {
// 		return newfunction, err
// 	}

// 	return newfunction, nil
// }
    </file>    <file name="messages.go">
        package agent

// Package messages contains functions to edit an agent&#39;s message chain

import (
	// &quot;AgentSmithU/agent&quot;

	&quot;fmt&quot;
	&quot;regexp&quot;
	&quot;sort&quot;
	&quot;strconv&quot;
)

type Messages []Message

type Message struct {
	Role    string `json:&quot;role&quot;`
	Content string `json:&quot;content&quot;`
}

type PromptDefinition struct {
	Name        string
	Description string
	Parameters  string
}

// Add new message to message chain
func (m *Messages) Add(role, content string) {
	*m = append(*m, Message{Role: role, Content: content})
}

// Makes numbered messages empty
// This &#39;clears&#39; lines to &#39;_&#39;
// Deleting lines is a two-step process because I needed a way to
// keep track of what was deleted in the gui - it was basically a choice
// between reloading the page each delete (ie rewriting/resyncing html/
// backend index) or keeping a record of cleared lines and refreshing
// only on reload
func (m *Messages) Clearlines(editchoice string) error {
	// Use regular expression to find all numerical segments in the input string
	reg := regexp.MustCompile(&quot;[0-9]+&quot;)
	nums := reg.FindAllString(editchoice, -1)

	var sortednums []int
	// Convert each numerical string to integer and sort
	for _, numStr := range nums {
		num, err := strconv.Atoi(numStr)
		if err != nil {
			return err
		}
		sortednums = append(sortednums, num)
	}

	sort.Ints(sortednums)
	fmt.Println(&quot;Clearing lines: &quot;, sortednums)

	// go from highest to lowest to not fu the order
	// for i := len(sortednums) - 1; i &gt;= 0; i-- {
	// 	agent.Messages = append(agent.Messages[:sortednums[i]], agent.Messages[sortednums[i]+1:]...)
	// }
	newmessages := *m

	for _, num := range sortednums {
		newmessages[num].Content = &quot;_&quot;
	}

	*m = newmessages

	return nil
}

// Deletes lines marked for deletion
// Clearlines marks lines for deletion with a &#39;_&#39; - Deletelines
// is used to actually remove them on page reload for gui
func (m *Messages) Deletelines() {
	messages := *m
	// remove empty messages
	// figure out what they are first
	var emptymessages []int
	for i, item := range messages {
		if item.Content == &quot;_&quot; {
			emptymessages = append(emptymessages, i)
		}
	}

	// sort the numbers and start from top
	sort.Ints(emptymessages)
	fmt.Println(&quot;Deleting lines: &quot;, emptymessages)

	for i := len(emptymessages) - 1; i &gt;= 0; i-- {
		messages = append(messages[:emptymessages[i]], messages[emptymessages[i]+1:]...)
	}
	*m = messages
}
    </file>    <request>
        can you look over these files and tell me how i can make the code more efficient?
    </request></data>
